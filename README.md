# ğŸ§  Modelo de PredicciÃ³n de Salud Mental  
Sistema de Machine Learning para predecir si una persona podrÃ­a requerir tratamiento de salud mental, usando mÃºltiples algoritmos de clasificaciÃ³n y un flujo completo de anÃ¡lisis de datos (EDA â†’ Preprocesamiento â†’ Modelos â†’ MÃ©tricas â†’ Visualizaciones).

---

## ğŸš€ Abrir el Proyecto en Google Colab  
Haz clic aquÃ­ para ver y ejecutar el notebook en lÃ­nea:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/julianguerra1231186-crypto/AI-julianguerra/blob/main/ModeloDePrediccionSaludMental.ipynb)

---

## ğŸ“Œ Â¿QuÃ© hace este proyecto?

ğŸ”¹ Limpia, codifica y balancea un dataset de salud mental  
ğŸ”¹ Realiza un EDA completo con visualizaciones  
ğŸ”¹ Entrena 3 modelos de clasificaciÃ³n (Naive Bayes, Decision Tree, SVM)  
ğŸ”¹ Optimiza modelos con GridSearchCV  
ğŸ”¹ Compara rendimiento con mÃºltiples mÃ©tricas  
ğŸ”¹ Genera grÃ¡ficas obligatorias para el taller  

---

# ğŸ§© CÃ³mo solucionamos el taller â€” ExplicaciÃ³n Paso a Paso

## 1ï¸âƒ£ PreparaciÃ³n del entorno  
- Importamos librerÃ­as principales: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`.  
- Cargamos el dataset `Mentaldataset1.csv`.  
- Revisamos estructura con `head()`, `info()`, `describe()`.

---

## 2ï¸âƒ£ Limpieza del dataset  
- Identificamos valores faltantes mediante `isnull().sum()`.  
- Eliminamos filas incompletas con `dropna()` para garantizar consistencia.  

---

## 3ï¸âƒ£ CodificaciÃ³n de variables categÃ³ricas  
- Usamos `LabelEncoder` para todas las columnas categÃ³ricas (gÃ©nero, paÃ­s, ocupaciÃ³n, historial familiar, etc.).  
- Esto permite que los modelos trabajen con datos numÃ©ricos.

---

## 4ï¸âƒ£ EDA â€” AnÃ¡lisis Exploratorio de Datos  
Realizamos un anÃ¡lisis visual y estadÃ­stico:

ğŸ“Š Histogramas â†’ distribuciÃ³n general  
ğŸ”¥ Heatmaps â†’ correlaciones Pearson, Spearman y Kendall  
ğŸ“‰ DetecciÃ³n del problema principal: **desbalance de la variable objetivo** (`Treatment`)

---

## 5ï¸âƒ£ Balanceo del dataset  
- Aplicamos **oversampling** con `resample` para equilibrar ambas clases.  
- Esto previene que los modelos se sesguen hacia la clase mayoritaria.

---

## 6ï¸âƒ£ DivisiÃ³n del dataset  
- Definimos `X` (features) e `y` (target: `Treatment`).  
- Dividimos en 80% entrenamiento y 20% prueba con `train_test_split`.

---

## 7ï¸âƒ£ Entrenamiento de modelos  
Entrenamos y evaluamos:

### ğŸ§ª **1. Naive Bayes (GaussianNB)**
- Entrenamiento base  
- MÃ©tricas: precisiÃ³n, recall, F1-score  
- OptimizaciÃ³n con `GridSearchCV`

### ğŸŒ³ **2. Decision Tree**
- Entrenamiento base  
- Importancia de variables (`feature_importances_`)  
- OptimizaciÃ³n con grid search  

### âš™ï¸ **3. SVM (Support Vector Machine)**  
- Datos escalados con `StandardScaler`  
- MÃ©tricas completas  

---

## 8ï¸âƒ£ Visualizaciones obligatorias  
Incluimos:

ğŸ“Œ **Heatmap de correlaciones**  
ğŸ“Œ **GrÃ¡fico antes vs despuÃ©s del balanceo**  
ğŸ“Œ (Opcionales) Importancia de variables y matrices de confusiÃ³n  

---

## 9ï¸âƒ£ Reproducibilidad  
- Se estableciÃ³ `random_state` en todos los procesos aleatorios.  
- Se creÃ³ `requirements.txt` y `.gitignore` para mantener ordenado el proyecto.  

---

# â–¶ï¸ CÃ³mo ejecutar el proyecto localmente

```bash
pip install -r requirements.txt
python modelodeprediccionsaludmental.py
